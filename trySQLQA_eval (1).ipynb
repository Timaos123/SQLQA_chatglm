{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0805609d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "索引 'try_student_school_index' 已存在\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      " 33%|███▎      | 1/3 [00:15<00:31, 15.60s/it]Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      " 67%|██████▋   | 2/3 [00:31<00:15, 15.75s/it]Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 3/3 [00:47<00:00, 15.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功插入Elasticsearch索引： try_student_school_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base were not used when initializing RoFormerModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'roformer.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'roformer.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing RoFormerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoFormerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoFormerModel were not initialized from the model checkpoint at ./dependent_service/models--junnyu--roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketItem: [{'col_name': 'district', 'value': '南京'}]\n",
      "bucketItem: [{'col_name': 'school_name', 'value': '河海大学'}]\n",
      "bucketItem: [{'col_name': 'student_name', 'value': '张七'}]\n",
      "bucketItem: [{'col_name': '地区', 'value': '南京'}]\n",
      "bucketItem: [{'col_name': '姓名', 'value': '张七'}]\n",
      "column [\n",
      "    {\n",
      "        \"col_name\": \"district\",\n",
      "        \"value\": \"南京\"\n",
      "    },\n",
      "    {\n",
      "        \"col_name\": \"school_name\",\n",
      "        \"value\": \"河海大学\"\n",
      "    },\n",
      "    {\n",
      "        \"col_name\": \"student_name\",\n",
      "        \"value\": \"张七\"\n",
      "    },\n",
      "    {\n",
      "        \"col_name\": \"地区\",\n",
      "        \"value\": \"南京\"\n",
      "    },\n",
      "    {\n",
      "        \"col_name\": \"姓名\",\n",
      "        \"value\": \"张七\"\n",
      "    }\n",
      "]\n",
      "colList: [{'col_name': 'district', 'value': '南京'}, {'col_name': 'school_name', 'value': '河海大学'}, {'col_name': 'student_name', 'value': '张七'}, {'col_name': '地区', 'value': '南京'}, {'col_name': '姓名', 'value': '张七'}] []\n",
      "prompt: 我们拥有如下数据：\n",
      " school_df:\n",
      "|    | district   | student_name   | school_name   |\n",
      "|---:|:-----------|:---------------|:--------------|\n",
      "|  3 | 北京       | 张六           | 北京大学      |\n",
      "|  0 | 北京       | 张三           | 清华大学      |\n",
      "|  2 | 赣州       | 张五           | 清华大学      |\n",
      "|  1 | 南京       | 张四           | 清华大学      |\n",
      "|  4 | 南京       | 张七           | 北京大学      |\n",
      "请根据以上数据以及用户问题：'哪个学校学生数最多？'\n",
      "构建SQL解答用户问题。\n",
      "构建SQL的时候注意使用和返回原表的字段（`district` 或 `student_name` 或 `school_name`），不要使用*，答案只需要sql，使用GROUP BY的时候注意你的聚合函数和使用的字段是什么，不需要别的解释，请用以下格式生成SQL：\n",
      "生成的SQL为：```你生成的SQL```\n",
      "\n",
      "注意原表内容\n",
      "用户问题是：'哪个学校学生数最多？'\n",
      "生成的SQL为：\n",
      "table:   district student_name school_name\n",
      "3       北京           张六        北京大学\n",
      "0       北京           张三        清华大学\n",
      "2       赣州           张五        清华大学\n",
      "1       南京           张四        清华大学\n",
      "4       南京           张七        北京大学\n",
      "SQLQuery:    \\nSELECT school_name, COUNT(*) as student_count  \\nFROM school_df  \\nGROUP BY school_name  \\nORDER BY student_count DESC  \\nLIMIT 1;  \\n\n",
      "回答: \" 你的答案是：清华大学有最多的学生，共有 3 名学生。\"\n",
      "查询结果:   school_name  student_count\n",
      "0        清华大学              3\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "import http.client\n",
    "import json\n",
    "import requests\n",
    "import torch\n",
    "import pandas as pd\n",
    "from new_A0_try_input_Text2SQL import insert_into_es\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def encode_text(bert_model, bert_tokenizer, text):\n",
    "    inputs = bert_tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return embeddings\n",
    "\n",
    "def search_similar_vectors(query_text, indexName=\"sqlqa_index\", \n",
    "                                        simVal=\"content\",\n",
    "                                        simVec=\"content_vector\",\n",
    "                                        simType=\"column\",top_k=5):\n",
    "    # 返回近似字段\n",
    "    # simType: column/value\n",
    "    \n",
    "    model = AutoModel.from_pretrained(\"./dependent_service/models--junnyu--roformer_chinese_sim_char_base\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./dependent_service/models--junnyu--roformer_chinese_sim_char_base\",trust_remote_code=True)\n",
    "#     query_vector=encode_text(model, tokenizer, query_text)\n",
    "    input_ids = tokenizer(query_text, return_tensors='pt', truncation=True, padding=True)['input_ids']\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    query_vector=outputs.last_hidden_state.mean(dim=1).squeeze(0).numpy()\n",
    "        \n",
    "    if simType==\"column\":\n",
    "        body = {\n",
    "                    \"size\": 5,\n",
    "                    \"query\": {\n",
    "                        \"function_score\": {\n",
    "                            \"query\": {\"match_all\": {}},\n",
    "                            \"script_score\": {\n",
    "                                \"script\": {\n",
    "                                    \"source\": \"cosineSimilarity(params.query_vector, doc['col_name_vec']) + \\\n",
    "                                                cosineSimilarity(params.query_vector, doc['value_vec'])+\\\n",
    "                                                1.0\",\n",
    "                                    \"params\": {\"query_vector\": query_vector.flatten().tolist()}\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"_source\": [\"col_name\", \"value\"],  # 返回指定字段\n",
    "                    \"aggs\": {\n",
    "                        \"deduplicate\": {\n",
    "                            \"terms\": {\n",
    "                                \"field\": \"col_name\",\n",
    "                                \"size\":5\n",
    "                            },\n",
    "                            \"aggs\": {\n",
    "                                \"top_hits\": {\n",
    "                                    \"top_hits\": {\n",
    "                                        \"size\": 1  # 每个分组返回的文档数量，这里设为1代表只选择每组中的第一个文档\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "    else:\n",
    "        body = {\n",
    "                    \"size\": 5,\n",
    "                    \"query\": {\n",
    "                        \"function_score\": {\n",
    "                            \"query\": {\"match_all\": {}},\n",
    "                            \"script_score\": {\n",
    "                                \"script\": {\n",
    "                                    \"source\": \"cosineSimilarity(params.query_vector, doc['col_name_vec']) + \\\n",
    "                                                cosineSimilarity(params.query_vector, doc['value_vec'])+\\\n",
    "                                                1.0\",\n",
    "                                    \"params\": {\"query_vector\": query_vector.flatten().tolist()}\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"_source\": [\"col_name\", \"value\"],  # 返回指定字段\n",
    "                    \"aggs\": {\n",
    "                        \"deduplicate\": {\n",
    "                            \"terms\": {\n",
    "                                \"field\": \"value\",\n",
    "                                \"size\":5\n",
    "                            },\n",
    "                            \"aggs\": {\n",
    "                                \"top_hits\": {\n",
    "                                    \"top_hits\": {\n",
    "                                        \"size\": 1  # 每个分组返回的文档数量，这里设为1代表只选择每组中的第一个文档\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "    \n",
    "    buckets = es.search(index=indexName, body=body)\n",
    "    for bucketItem in buckets[\"aggregations\"][\"deduplicate\"][\"buckets\"]:\n",
    "        print(\"bucketItem:\",[{\"col_name\":row[\"_source\"][\"col_name\"],\"value\":row[\"_source\"][\"value\"]} for row in bucketItem[\"top_hits\"][\"hits\"][\"hits\"]])\n",
    "    response=[row[\"_source\"] for bucketItem in buckets[\"aggregations\"][\"deduplicate\"][\"buckets\"]\n",
    "                              for row in bucketItem[\"top_hits\"][\"hits\"][\"hits\"]]\n",
    "    response=[{\"col_name\":row[\"col_name\"],\"value\":row[\"value\"]} for row in response]\n",
    "    print(simType,json.dumps(response,indent=4,ensure_ascii=False))\n",
    "#     print(simType,response)# [0][\"_source\"]\n",
    "    return response\n",
    "\n",
    "\n",
    "def search_similar_text(query_text, \n",
    "                        indexName=\"sqlqa_index\", \n",
    "                        simVal=\"col_name\",\n",
    "                        simType=\"column\", top_k=5):\n",
    "    # simType: column/value\n",
    "    if simType==\"column\":\n",
    "        body = {\n",
    "            \"size\": 0,\n",
    "            \"aggs\": {\n",
    "                \"deduplicated_values\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": simVal,\n",
    "                        \"size\": top_k\n",
    "                    },\n",
    "                    \"aggs\": {\n",
    "                        \"top_hits\": {\n",
    "                            \"top_hits\": {\n",
    "                                \"size\": 1  # 每个分组返回的文档数量，这里设为1代表只选择每组中的第一个文档\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    simVal: {\n",
    "                        \"query\": query_text,\n",
    "                        \"fuzziness\": \"AUTO\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        # # print(body)\n",
    "        # response = es.search(index=indexName, body=body)[\"aggs\"][\"hits\"][\"hits\"]\n",
    "        # response=[row[\"_source\"] for row in response]\n",
    "    else:\n",
    "        body = {\n",
    "            \"size\": 0,\n",
    "            \"aggs\": {\n",
    "                \"deduplicated_values\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": simVal,\n",
    "                        \"size\": top_k\n",
    "                    },\n",
    "                    \"aggs\": {\n",
    "                        \"top_hits\": {\n",
    "                            \"top_hits\": {\n",
    "                                \"size\": 1  # 每个分组返回的文档数量，这里设为1代表只选择每组中的第一个文档\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    simVal: {\n",
    "                        \"query\": query_text,\n",
    "                        \"fuzziness\": \"2\",\n",
    "                        \"prefix_length\": 1,\n",
    "                        \"max_expansions\": 50\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    buckets = es.search(index=indexName, body=body)[\"aggregations\"][\"deduplicated_values\"][\"buckets\"]\n",
    "    response=[]\n",
    "    for bucketItem in buckets:\n",
    "        response+=bucketItem[\"top_hits\"][\"hits\"][\"hits\"]\n",
    "    response=[row[\"_source\"] for row in response]\n",
    "    return response\n",
    "\n",
    "def get_related_columns(user_text,indexName=\"sqlqa_index\"):\n",
    "    # 基于文本的向量近似度和关键词近似度处理逻辑\n",
    "    \n",
    "    # 近似列\n",
    "    colList1=search_similar_vectors(user_text, \n",
    "                                    indexName=indexName,\n",
    "                                    simType=\"column\",\n",
    "                                    simVec=\"col_name_vec\",\n",
    "                                    simVal=\"col_name\", top_k=3)\n",
    "    colList2=search_similar_text(user_text, \n",
    "                                    indexName=indexName, \n",
    "                                    simType=\"column\",\n",
    "                                    simVal=\"col_name\",\n",
    "                                    top_k=3)\n",
    "    colList=colList1+colList2\n",
    "    print(\"colList:\",colList1,colList2)\n",
    "    colList=[colItem[\"col_name\"] for colItem in colList]\n",
    "    colList=list(set(colList))\n",
    "    \n",
    "    return colList\n",
    "\n",
    "def get_related_values(user_text):\n",
    "    # 在ES中查询与单引号内最相近的5个值的逻辑\n",
    "    # 近似值\n",
    "    valList1=search_similar_vectors(user_text, \n",
    "                                    indexName=indexName,\n",
    "                                    simType=\"value\",\n",
    "                                    simVec=\"value_vec\",\n",
    "                                    simVal=\"value\", top_k=3)\n",
    "    valList2=search_similar_text(user_text, \n",
    "                                    indexName=indexName,\n",
    "                                    simVal=\"value\",\n",
    "                                    simType=\"value\",\n",
    "                                    top_k=3)\n",
    "    valList=valList1+valList2\n",
    "    valList=[(row[\"col_name\"],row[\"value\"]) for row in valList]\n",
    "    valList=list(set(map(lambda row:str(row),valList)))\n",
    "    valList=list(map(lambda row:eval(row),valList))\n",
    "    valList=list(filter(lambda row:row[1]!=\"num\",valList))\n",
    "    valDict=dict(valList)\n",
    "    \n",
    "    return valDict\n",
    "\n",
    "def retrieve_sample_table(myDf,relevant_fields,sampleN=5):\n",
    "    # 从数据库中获取样本表格的逻辑\n",
    "    real_relevant_fields=filter(lambda colItem:colItem in myDf.columns,relevant_fields)\n",
    "    return myDf.loc[:,real_relevant_fields].sample(min(sampleN,myDf.shape[0]))\n",
    "\n",
    "def chatGLM(prompt):\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "#     url = \"http://172.2.0.97:6006/beauty_industry_doc_qa\"\n",
    "    url = \"http://127.0.0.1:6006/chatglm/generate_content\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"prompt\":prompt\n",
    "    })\n",
    "    headers = {\n",
    "        'User-Agent': 'Apifox/1.0.0 (https://www.apifox.cn)',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': '*/*',\n",
    "        'Host': '127.0.0.1:6006',\n",
    "        'Connection': 'keep-alive'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "#     print(response.text)\n",
    "    \n",
    "    return response.json()[\"data\"]\n",
    "\n",
    "def construct_base_sql(user_text,sample_table,table_name=\"school_df\",falseQueryList=[]):\n",
    "    # 基于样本表格构建基础的SQL的逻辑\n",
    "    prompt=\"我们拥有如下数据：\\n {}:\\n{}\\n\".format(table_name,sample_table.to_markdown()) + \\\n",
    "            \"请根据以上数据以及用户问题：'{}'\\n\".format(user_text)+ \\\n",
    "            \"构建SQL解答用户问题。\\n\"+\\\n",
    "            \"构建SQL的时候注意使用和返回原表的字段（{}），不要使用*，答案只需要sql，使用GROUP BY的时候注意你的聚合函数和使用的字段是什么，不需要别的解释，请用以下格式生成SQL：\\n\".format(\" 或 \".join(map(lambda colItem:\"`{}`\".format(colItem),list(sample_table.columns))))+\\\n",
    "            \"生成的SQL为：```你生成的SQL```\\n\"+\\\n",
    "            (\"你之前生成过如下错误SQL：\\n\"+\";\\n\".join(falseQueryList)+\"\\n注意不要重复以上错误SQL\\n\" if len(falseQueryList)>0 else \"\")+\"\\n注意原表内容\\n\"+\\\n",
    "            \"用户问题是：'{}'\\n\".format(user_text)+ \\\n",
    "            \"生成的SQL为：\"\n",
    "    print(\"prompt:\",prompt)\n",
    "    SQLResult=chatGLM(prompt)\n",
    "    return SQLResult\n",
    "\n",
    "def check_quotes(base_sql):\n",
    "    if \"'\" in base_sql:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def construct_new_table(sample_table, attr_val_dict):\n",
    "    # 构建新的样例表格的逻辑\n",
    "    print(\"attr_val_dict:\",attr_val_dict)\n",
    "    matchEvalStr=\"|\".join([\"(sample_table['{}']=='{}')\".format(k,v) \n",
    "                                   for k,v in attr_val_dict.items()\n",
    "                                      if k in sample_table.columns])\n",
    "    print(\"matchEvalStr:\",matchEvalStr)\n",
    "    if len(matchEvalStr)>0:\n",
    "        new_table=sample_table.loc[eval(matchEvalStr),:]\n",
    "    else:\n",
    "        new_table=sample_table\n",
    "    return new_table\n",
    "\n",
    "def reconstruct_sql(base_sql, user_text):\n",
    "    # 重构SQL，结合用户输入的文本的逻辑\n",
    "    # ...\n",
    "    return reconstructed_sql\n",
    "\n",
    "import duckdb\n",
    "def execute_sql(reconstructed_sql,myDf,table_name=\"school_df\"):\n",
    "    # 执行SQL检索的逻辑\n",
    "    # df = pd.DataFrame({'name': ['Alice', 'Bob', 'Charlie'], 'age': [25, 30, 35]})\n",
    "\n",
    "    con = duckdb.connect()\n",
    "    con.register(table_name, myDf)\n",
    "\n",
    "    result = con.execute(reconstructed_sql.replace(\"\\\\n\",\"\"))\n",
    "    df_result = result.fetchdf()\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "def generate_answer(user_text, newSQL,sample_table,query_result,table_name=\"school_df\"):\n",
    "    # 结合用户输入的问题和SQL检索结果生成回答的逻辑\n",
    "    prompt=\"我们拥有如下数据：\\n {}:\\n{}\\n\".format(table_name,sample_table.to_markdown()) + \\\n",
    "            \"请根据以上数据以及用户问题：'{}'\\n\".format(user_text)+ \\\n",
    "            \"构建SQL解答用户问题。\\n\"+\\\n",
    "            \"构建SQL的时候注意使用和返回原表的字段（{}），注意原表内容，不要使用*，答案只需要sql，使用GROUP BY的时候注意你的聚合函数和使用的字段是什么，不需要别的解释，请用以下格式生成SQL：\\n\".format(\" 或 \".join(map(lambda colItem:\"`{}`\".format(colItem),list(sample_table.columns))))+\\\n",
    "            \"生成的SQL为：```你生成的SQL```\\n\"+\\\n",
    "            \"用户问题是：'{}'\\n\".format(user_text)+ \\\n",
    "            \"生成的SQL为：```{}```\\n\".format(newSQL)+\\\n",
    "            \"所得结果为：\\n{}\".format(query_result.to_markdown())+\\\n",
    "            \"根据以上数据回答用户问题'{}'，回答格式如下：\\n\".format(user_text)+\\\n",
    "            \"你的回答是：```你的答案```\\n\"+\\\n",
    "            \"你的回答是：\"\n",
    "    answer=chatGLM(prompt)\n",
    "    return answer\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "def find_most_similar_string(str1, string_list):\n",
    "    return process.extractOne(str1, string_list)[0]\n",
    "    \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # 用户输入文本\n",
    "    user_text = \"哪个学校学生数最多？\"\n",
    "    # 示例DataFrame\n",
    "    myDf = pd.DataFrame(\n",
    "        [[\"张三\",\"清华大学\",\"北京\"],\n",
    "        [\"张四\",\"清华大学\",\"南京\"],\n",
    "        [\"张五\",\"清华大学\",\"赣州\"],\n",
    "        [\"张六\",\"北京大学\",\"北京\"],\n",
    "        [\"张七\",\"北京大学\",\"南京\"],\n",
    "        [\"张八\",\"对外经济贸易大学\",\"赣州\"],\n",
    "        [\"张九\",\"河海大学\",\"北京\"]],columns=[\"student_name\",\"school_name\",\"district\"])\n",
    "    indexName = \"try_student_school_index\"  # 设置Elasticsearch索引的名称\n",
    "    id_col_name = \"student_name\"  # 用户提供的id列名\n",
    "    table_name=\"school_df\"\n",
    "    \n",
    "    # 初始化Elasticsearch\n",
    "    es = Elasticsearch(hosts=[\"http://127.0.0.1:9200\"])\n",
    "    \n",
    "    insert_into_es(myDf,es,indexName,id_col_name)\n",
    "\n",
    "    # 处理输入文本，获取相关字段\n",
    "    relevant_fields = get_related_columns(user_text,indexName=indexName)\n",
    "\n",
    "    # 从数据库中获取样本表格\n",
    "    sample_table = retrieve_sample_table(myDf,relevant_fields)\n",
    "\n",
    "    # 构建基础的SQL查询语句\n",
    "    falseQueryList=[]\n",
    "    while True:\n",
    "        if len(falseQueryList)>3:\n",
    "            break\n",
    "        try:\n",
    "            base_sql = construct_base_sql(user_text,sample_table,table_name=table_name,falseQueryList=falseQueryList)\n",
    "            base_sql=base_sql.replace(\"\\\"\",\"\").replace(\"`\",\"\").replace(\"，\",\",\")\n",
    "\n",
    "            # 判断SQL中是否存在单引号\n",
    "            if check_quotes(base_sql):\n",
    "                # 在ES中查询与单引号内最相近的5个值\n",
    "                attr_val_dict = get_related_values(user_text)\n",
    "\n",
    "                # 构建新的样例表格\n",
    "                new_table = construct_new_table(sample_table, attr_val_dict)\n",
    "\n",
    "                # 重构SQL查询语句，结合用户输入的文本\n",
    "                sqlKVList=re.findall(\"\\S*\\s+=\\s+'.*?'\",base_sql)\n",
    "                for sqlKVItem in sqlKVList:\n",
    "                    k,v=sqlKVItem.split(\"=\")\n",
    "                    k=k.strip()\n",
    "                    if \".\" in k:\n",
    "                        k=k.split(\".\")[1]\n",
    "                    v=v.replace(\"'\",\"\").strip()\n",
    "                    newVList=new_table[k].values.flatten().tolist()\n",
    "                    newV=find_most_similar_string(v,newVList)\n",
    "                    base_sql=base_sql.replace(v,newV)\n",
    "\n",
    "                reconstructed_sql = base_sql\n",
    "            else:\n",
    "                new_table = sample_table\n",
    "                reconstructed_sql = base_sql\n",
    "\n",
    "            print(\"table:\",new_table)\n",
    "            print(\"SQLQuery:\",reconstructed_sql)\n",
    "            # 执行SQL查询\n",
    "            query_result = execute_sql(reconstructed_sql,myDf,table_name=table_name)\n",
    "            break\n",
    "        except duckdb.BinderException as de:\n",
    "            traceback.print_exc()\n",
    "            falseQueryList.append(reconstructed_sql)\n",
    "#             falseQueryList=list(set(falseQueryList))\n",
    "        except duckdb.ParserException as dp:\n",
    "            traceback.print_exc()\n",
    "            falseQueryList.append(reconstructed_sql)\n",
    "#             falseQueryList=list(set(falseQueryList))\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            \n",
    "\n",
    "    # 生成回答\n",
    "    answer = generate_answer(user_text,reconstructed_sql, sample_table,query_result,table_name=table_name)\n",
    "\n",
    "    # 输出结果\n",
    "    if \"你的回答是：\" in answer:\n",
    "        answer=answer.split(\"你的回答是：\")[1]\n",
    "        answer=answer.replace(\"\\\"\",\"\")\n",
    "        \n",
    "    print(\"回答:\", answer)\n",
    "        \n",
    "    print(\"查询结果:\", query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116edadf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['姓名', 'district', 'school_name', '地区', '学校']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ff3f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   \\\\nSELECT 地址，学校，学生数  \\\\nFROM school_df  \\\\nGROUP BY 地址  \\\\nORDER BY 学生数 DESC  \\\\nLIMIT 1;  \\\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16413be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>学校</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>对外经济贸易大学</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         学校\n",
       "0  对外经济贸易大学"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "def execute_sql(reconstructed_sql,myDf,table_name=\"school_df\"):\n",
    "    # 执行SQL检索的逻辑\n",
    "    # df = pd.DataFrame({'name': ['Alice', 'Bob', 'Charlie'], 'age': [25, 30, 35]})\n",
    "\n",
    "    con = duckdb.connect()\n",
    "    con.register(table_name, myDf)\n",
    "\n",
    "    result = con.execute(reconstructed_sql.replace(\"\\\\n\",\"\"))\n",
    "    df_result = result.fetchdf()\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "sample_table = pd.DataFrame({\n",
    "        '学校': ['清华大学', '北京大学', '对外经济贸易大学'],\n",
    "        '地址': ['北京', '湖南', '河北'],\n",
    "        '学生数': [128, 211, 985]\n",
    "    })\n",
    "\n",
    "execute_sql(\"SELECT 学校 FROM school_df GROUP BY 学校 ORDER BY 学生数 DESC LIMIT 1  \",\n",
    "            sample_table,\n",
    "            table_name=\"school_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9462bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      3\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      4\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      5\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_all\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}},\n\u001b[1;32m      6\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscript_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      7\u001b[0m                                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      8\u001b[0m                                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosineSimilarity(params.query_vector, doc[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_name_vec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]) + \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m                                                cosineSimilarity(params.query_vector, doc[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_vec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])+\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m                                                1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 11\u001b[0m                                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mquery_vector\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()}\n\u001b[1;32m     12\u001b[0m                                 }\n\u001b[1;32m     13\u001b[0m                             }\n\u001b[1;32m     14\u001b[0m                         }\n\u001b[1;32m     15\u001b[0m                     },\n\u001b[1;32m     16\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],  \u001b[38;5;66;03m# 返回指定字段\u001b[39;00m\n\u001b[1;32m     17\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggs\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     18\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeduplicate\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     19\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterms\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     20\u001b[0m                                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m                                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 这里可以根据你的需求调整大小\u001b[39;00m\n\u001b[1;32m     22\u001b[0m                             },\n\u001b[1;32m     23\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggs\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     24\u001b[0m                                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_hits\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     25\u001b[0m                                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_hits\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     26\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 每个分组返回的文档数量，这里设为1代表只选择每组中的第一个文档\u001b[39;00m\n\u001b[1;32m     27\u001b[0m                                     }\n\u001b[1;32m     28\u001b[0m                                 }\n\u001b[1;32m     29\u001b[0m                             }\n\u001b[1;32m     30\u001b[0m                         }\n\u001b[1;32m     31\u001b[0m                     }\n\u001b[1;32m     32\u001b[0m                 }\n\u001b[1;32m     33\u001b[0m buckets \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39msearch(index\u001b[38;5;241m=\u001b[39mindexName, body\u001b[38;5;241m=\u001b[39mbody)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query_vector' is not defined"
     ]
    }
   ],
   "source": [
    "body = {\n",
    "                    \"size\": 5,\n",
    "                    \"query\": {\n",
    "                        \"function_score\": {\n",
    "                            \"query\": {\"match_all\": {}},\n",
    "                            \"script_score\": {\n",
    "                                \"script\": {\n",
    "                                    \"source\": \"cosineSimilarity(params.query_vector, doc['col_name_vec']) + \\\n",
    "                                                cosineSimilarity(params.query_vector, doc['value_vec'])+\\\n",
    "                                                1.0\",\n",
    "                                    \"params\": {\"query_vector\": query_vector.flatten().tolist()}\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"_source\": [\"col_name\"],  # 返回指定字段\n",
    "                    \"aggs\": {\n",
    "                        \"deduplicate\": {\n",
    "                            \"terms\": {\n",
    "                                \"field\": \"col_name\",\n",
    "                                \"size\": 1  # 这里可以根据你的需求调整大小\n",
    "                            },\n",
    "                            \"aggs\": {\n",
    "                                \"top_hits\": {\n",
    "                                    \"top_hits\": {\n",
    "                                        \"size\": 1  # 每个分组返回的文档数量，这里设为1代表只选择每组中的第一个文档\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "buckets = es.search(index=indexName, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce01e00a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('学校', '清华大学'),\n",
       " ('学校', '北京大学'),\n",
       " ('学校', '对外经济贸易大学'),\n",
       " ('学生数', 'num'),\n",
       " ('学生数', 'num')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(row[\"_source\"][\"col_name\"], row[\"_source\"][\"value\"]) for row in buckets[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05b3774d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'try_sql_index': {'mappings': {'properties': {'col_name': {'type': 'keyword'},\n",
       "    'col_name_vec': {'type': 'dense_vector', 'dims': 768},\n",
       "    'id_col_name': {'type': 'keyword'},\n",
       "    'id_col_name_val': {'type': 'keyword'},\n",
       "    'row_i': {'type': 'integer'},\n",
       "    'value': {'type': 'keyword'},\n",
       "    'value_vec': {'type': 'dense_vector', 'dims': 768}}}}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.get_mapping(index=indexName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b059101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index=indexName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "performpredict",
   "language": "python",
   "name": "performpredict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
